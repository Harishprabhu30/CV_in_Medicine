{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78141b5d",
   "metadata": {},
   "source": [
    "# Lab 3 â€” CNNs for Microscopy Image Analysis\n",
    "**Models:** U-Net (semantic segmentation) + StarDist (instance segmentation)\n",
    "\n",
    "**Objective:** \n",
    "- Test two very different CNNs on microscopy images.\n",
    "- Observe strengths, weaknesses, and visualize results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77436213",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3565984541.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m**Models:** U-Net (semantic segmentation) + StarDist (instance segmentation)\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 1) Imports and setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "from skimage import measure\n",
    "\n",
    "# Paths\n",
    "ROOT = Path.cwd()\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"LD4_images\"\n",
    "OUTPUTS = ROOT / \"outputs\"\n",
    "IMGS_OUT = OUTPUTS / \"images\"\n",
    "METRICS_DIR = OUTPUTS / \"metrics\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "\n",
    "for p in [DATA_DIR, RAW_DIR, OUTPUTS, IMGS_OUT, METRICS_DIR, MODELS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Download LD4 images (Dropbox)\n",
    "dropbox_url = \"https://www.dropbox.com/s/qscq5qa5v5nbwxi/LD4_images.zip?dl=1\"\n",
    "\n",
    "if not any(RAW_DIR.iterdir()):\n",
    "    print(\"Downloading LD4 images...\")\n",
    "    r = requests.get(dropbox_url, stream=True)\n",
    "    r.raise_for_status()\n",
    "    z = zipfile.ZipFile(BytesIO(r.content))\n",
    "    z.extractall(RAW_DIR)\n",
    "    print(\"Extracted to\", RAW_DIR)\n",
    "else:\n",
    "    print(\"LD4 images already exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe53fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load images\n",
    "img_paths = sorted([p for p in RAW_DIR.rglob(\"*\") if p.suffix.lower() in [\".png\",\".jpg\",\".tif\"]])\n",
    "print(f\"Found {len(img_paths)} images\")\n",
    "\n",
    "def load_image(path):\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    return np.array(im)\n",
    "\n",
    "def show_image(im, title=None):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(im)\n",
    "    if title: plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Show sample\n",
    "if img_paths:\n",
    "    show_image(load_image(img_paths[0]), \"Sample Image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff292db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Preprocessing functions\n",
    "def rescale_uint8(img):\n",
    "    imin, imax = img.min(), img.max()\n",
    "    if imax==imin: return np.zeros_like(img, dtype=np.uint8)\n",
    "    out = ((img - imin)/(imax-imin)*255).astype(np.uint8)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7da092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Build U-Net\n",
    "ENCODER = \"resnet34\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "def build_unet():\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        in_channels=3,\n",
    "        classes=NUM_CLASSES,\n",
    "        activation=None\n",
    "    )\n",
    "    return model\n",
    "\n",
    "unet = build_unet().to(DEVICE)\n",
    "unet.eval()\n",
    "preprocess_input = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "print(\"U-Net ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net prediction\n",
    "def unet_predict_image(image_cv, model, thresh=0.5):\n",
    "    x = preprocess_input(image_cv.astype('float32'))\n",
    "    x = np.transpose(x,(2,0,1))[None,...]\n",
    "    x = torch.from_numpy(x).float().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        prob = torch.sigmoid(logits).cpu().numpy()[0,0]\n",
    "    mask = prob > thresh\n",
    "    return mask, prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66384f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Load StarDist\n",
    "try:\n",
    "    stardist_model = StarDist2D.from_pretrained(\"2D_versatile_fluorescent\")\n",
    "    print(\"StarDist loaded\")\n",
    "except Exception:\n",
    "    stardist_model = StarDist2D(None, name=\"stardist_demo\", basedir=str(MODELS_DIR), n_rays=32, grid=(1,1))\n",
    "    print(\"StarDist demo model created (untrained)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StarDist prediction\n",
    "def stardist_predict_image(image_cv, model):\n",
    "    gray = cv2.cvtColor(image_cv, cv2.COLOR_RGB2GRAY)\n",
    "    img = normalize(gray.astype(np.float32), 1, 99.8)\n",
    "    labels, _ = model.predict_instances(img)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Overlay helper\n",
    "def overlay_mask_on_image(image_cv, mask, color=(255,0,0), alpha=0.4):\n",
    "    overlay = image_cv.copy()\n",
    "    color_arr = np.array(color,dtype=np.uint8).reshape(1,1,3)\n",
    "    overlay[mask>0] = (overlay[mask>0].astype(int)*(1-alpha) + color_arr*alpha).astype(np.uint8)\n",
    "    return overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Run inference on all images\n",
    "results_summary = []\n",
    "\n",
    "for p in img_paths:\n",
    "    im = load_image(p)\n",
    "    im = rescale_uint8(im)\n",
    "    \n",
    "    # U-Net\n",
    "    u_mask, _ = unet_predict_image(im, unet)\n",
    "    u_overlay = overlay_mask_on_image(im, u_mask, color=(255,0,0))\n",
    "    \n",
    "    # StarDist\n",
    "    sd_labels = stardist_predict_image(im, stardist_model)\n",
    "    sd_overlay = overlay_mask_on_image(im, sd_labels>0, color=(0,255,0))\n",
    "    \n",
    "    # Save overlays\n",
    "    base_name = p.stem\n",
    "    Image.fromarray(u_overlay).save(IMGS_OUT / f\"{base_name}_unet_overlay.png\")\n",
    "    Image.fromarray(sd_overlay).save(IMGS_OUT / f\"{base_name}_stardist_overlay.png\")\n",
    "    \n",
    "    results_summary.append({\n",
    "        \"image\": p.name,\n",
    "        \"unet_pixels\": int(u_mask.sum()),\n",
    "        \"stardist_instances\": int(sd_labels.max())\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results_summary).to_csv(METRICS_DIR / \"inference_summary.csv\", index=False)\n",
    "print(\"Inference complete. Results saved to outputs folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078bb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Show example results\n",
    "for i in range(min(3,len(img_paths))):\n",
    "    im = load_image(img_paths[i])\n",
    "    u_overlay = np.array(Image.open(IMGS_OUT / f\"{img_paths[i].stem}_unet_overlay.png\"))\n",
    "    sd_overlay = np.array(Image.open(IMGS_OUT / f\"{img_paths[i].stem}_stardist_overlay.png\"))\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im); plt.title(\"Original\"); plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(u_overlay); plt.title(\"U-Net Overlay\"); plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(sd_overlay); plt.title(\"StarDist Overlay\"); plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ca6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Robustness tests (optional)\n",
    "def add_noise(img, sigma=20):\n",
    "    noise = np.random.normal(0,sigma,img.shape).astype(np.float32)\n",
    "    return np.clip(img.astype(np.float32)+noise,0,255).astype(np.uint8)\n",
    "\n",
    "def add_blur(img, ksize=5):\n",
    "    return cv2.GaussianBlur(img,(ksize,ksize),0)\n",
    "\n",
    "def change_brightness(img,factor=0.6):\n",
    "    return np.clip(img.astype(np.float32)*factor,0,255).astype(np.uint8)\n",
    "\n",
    "robust_summary = []\n",
    "\n",
    "for p in img_paths[:3]:  # only first 3 for speed\n",
    "    im = load_image(p)\n",
    "    im = rescale_uint8(im)\n",
    "    variants = {\"noise\":add_noise(im),\"blur\":add_blur(im),\"dark\":change_brightness(im,0.6)}\n",
    "    \n",
    "    for vname,vimg in variants.items():\n",
    "        u_mask,_ = unet_predict_image(vimg,unet)\n",
    "        sd_labels = stardist_predict_image(vimg,stardist_model)\n",
    "        robust_summary.append({\n",
    "            \"image\":p.name,\n",
    "            \"variant\":vname,\n",
    "            \"unet_pixels\":int(u_mask.sum()),\n",
    "            \"stardist_instances\":int(sd_labels.max())\n",
    "        })\n",
    "\n",
    "pd.DataFrame(robust_summary).to_csv(METRICS_DIR / \"robustness_summary.csv\", index=False)\n",
    "print(\"Robustness summary saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869f05f",
   "metadata": {},
   "source": [
    "# 11) Optional Questions\n",
    "\n",
    "**1. Difficulties and solutions:**  \n",
    "- Installing stardist & tensorflow versions: solved by matching compatible versions.  \n",
    "- Image size mismatch for U-Net: solved by resizing before prediction.  \n",
    "\n",
    "**2. Best CNN architectures for microscopy:**  \n",
    "- **U-Net**: Excellent for semantic segmentation due to skip connections and localization.  \n",
    "- **StarDist**: Excellent for instance segmentation of star-shaped cells; handles overlapping cells.  \n",
    "\n",
    "**3. Own question:**  \n",
    "- *How do these networks behave on noisy images?*  \n",
    "- **Answer:** U-Net is robust to small noise but may merge/split regions; StarDist fails to detect faint or blurred objects.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV_Lab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
