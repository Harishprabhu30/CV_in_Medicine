{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51de4d3",
   "metadata": {},
   "source": [
    "# Lab 4 â€” Investigating Activation Map Features of CNNs (ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from math import ceil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as kimage\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0316827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "DATA_DIR = \"ePillID_data/classification_data/segmented_nih_pills_224\"  # path to folder of images\n",
    "NUM_SAMPLES = 500          # \"several hundred\" images to use (set between 300-600)\n",
    "IMG_SIZE = (224, 224)      # matches folder name and ResNet50 requirement\n",
    "BATCH_SIZE = 32\n",
    "NUM_QUERIES = 5            # must be >=5\n",
    "TOP_K = 10                 # find top-10 similar images\n",
    "RANDOM_SEED = 42\n",
    "SAVE_FEATURES = True       # set False if you don't want .npy saved\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Sanity check: dataset folder\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    raise FileNotFoundError(f\"DATA_DIR not found: {DATA_DIR}\\nDownload dataset from the release and extract, then set DATA_DIR accordingly.\")\n",
    "\n",
    "# collect image paths (common image extensions)\n",
    "patterns = [os.path.join(DATA_DIR, \"*.jpg\"), os.path.join(DATA_DIR, \"*.jpeg\"), os.path.join(DATA_DIR, \"*.png\")]\n",
    "img_paths = []\n",
    "for p in patterns:\n",
    "    img_paths.extend(glob(p))\n",
    "img_paths = sorted(img_paths)\n",
    "if len(img_paths) == 0:\n",
    "    raise FileNotFoundError(f\"No images found in {DATA_DIR}. Check the folder and that images are present.\")\n",
    "\n",
    "# sample NUM_SAMPLES images (no balancing, per strict requirements)\n",
    "if NUM_SAMPLES > len(img_paths):\n",
    "    NUM_SAMPLES = len(img_paths)\n",
    "sampled_paths = sorted(np.random.choice(img_paths, size=NUM_SAMPLES, replace=False))\n",
    "\n",
    "print(f\"Using {len(sampled_paths)} images from {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build ResNet50 model (include_top=False)\n",
    "#    We'll locate the last convolutional output tensor programmatically.\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Find the last convolutional layer by scanning layers in reverse for a 4D output (H x W x C)\n",
    "last_conv_layer = None\n",
    "for layer in reversed(base_model.layers):\n",
    "    if len(layer.output_shape) == 4:  # batch, H, W, C\n",
    "        last_conv_layer = layer.name\n",
    "        break\n",
    "if last_conv_layer is None:\n",
    "    raise RuntimeError(\"Could not find a last conv layer in ResNet50 model.\")\n",
    "\n",
    "print(\"Last convolutional layer:\", last_conv_layer)\n",
    "\n",
    "# Create a model that outputs the activation map of that last conv layer\n",
    "activation_model = tf.keras.Model(inputs=base_model.input, outputs=base_model.get_layer(last_conv_layer).output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Helper: image loading & preprocessing (returns batch of preprocessed arrays)\n",
    "def load_and_preprocess_image(path, target_size=IMG_SIZE):\n",
    "    # Load image with PIL via Keras, convert to array, resize, preprocess for ResNet50\n",
    "    img = kimage.load_img(path, target_size=target_size)\n",
    "    arr = kimage.img_to_array(img)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    arr = preprocess_input(arr)  # ResNet50 preprocessing\n",
    "    return arr  # shape (1, H, W, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Normalize feature vectors (L2) for cosine similarity (cosine similarity equals dot product after normalization)\n",
    "def l2_normalize_rows(mat):\n",
    "    norms = np.linalg.norm(mat, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    return mat / norms\n",
    "\n",
    "flat_norm = l2_normalize_rows(features[\"flatten\"])\n",
    "gmp_norm = l2_normalize_rows(features[\"gmp\"])\n",
    "gap_norm = l2_normalize_rows(features[\"gap\"])\n",
    "\n",
    "# Optionally save arrays to disk for reproducibility/reporting\n",
    "if SAVE_FEATURES:\n",
    "    out_dir = \"lab4_saved_features\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    np.save(os.path.join(out_dir, \"paths.npy\"), np.array(features[\"paths\"]))\n",
    "    np.save(os.path.join(out_dir, \"flatten.npy\"), features[\"flatten\"])\n",
    "    np.save(os.path.join(out_dir, \"flatten_norm.npy\"), flat_norm)\n",
    "    np.save(os.path.join(out_dir, \"gmp.npy\"), features[\"gmp\"])\n",
    "    np.save(os.path.join(out_dir, \"gmp_norm.npy\"), gmp_norm)\n",
    "    np.save(os.path.join(out_dir, \"gap.npy\"), features[\"gap\"])\n",
    "    np.save(os.path.join(out_dir, \"gap_norm.npy\"), gap_norm)\n",
    "    print(f\"Saved features to {out_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa1999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Cosine similarity search helpers\n",
    "def top_k_similar(normalized_features, query_index, k=10):\n",
    "    # normalized_features: (N, D) L2-normalized rows\n",
    "    # query_index: int index of query in the dataset\n",
    "    q = normalized_features[query_index:query_index+1]  # (1, D)\n",
    "    sims = np.dot(normalized_features, q.T).squeeze()  # (N,)\n",
    "    # exclude the query itself by setting its similarity to -inf\n",
    "    sims[query_index] = -np.inf\n",
    "    topk_idx = np.argsort(-sims)[:k]  # indices of top-k\n",
    "    topk_scores = sims[topk_idx]\n",
    "    return topk_idx, topk_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d243db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualization: show query image + top-K retrieved images with similarity scores\n",
    "# -------------------------\n",
    "def plot_query_and_results(paths, query_idx, retrieved_indices, retrieved_scores, title_prefix=\"\", figsize=(12,6)):\n",
    "    n_cols = TOP_K + 1\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    # Query on left\n",
    "    ax = fig.add_subplot(2, ceil((TOP_K+1)/2), 1)\n",
    "    qimg = kimage.load_img(paths[query_idx], target_size=IMG_SIZE)\n",
    "    ax.imshow(qimg)\n",
    "    ax.set_title(f\"Query\\nidx {query_idx}\")\n",
    "    ax.axis(\"off\")\n",
    "    # retrieved images\n",
    "    for i, (idx, score) in enumerate(zip(retrieved_indices, retrieved_scores), start=1):\n",
    "        ax = fig.add_subplot(2, ceil((TOP_K+1)/2), i+1)\n",
    "        rimg = kimage.load_img(paths[idx], target_size=IMG_SIZE)\n",
    "        ax.imshow(rimg)\n",
    "        ax.set_title(f\"{i}: idx {idx}\\n{score:.4f}\")\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(title_prefix, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Perform searches: Choose NUM_QUERIES random queries and display results for each feature type\n",
    "# -------------------------\n",
    "N = len(features[\"paths\"])\n",
    "if NUM_QUERIES > N:\n",
    "    NUM_QUERIES = N\n",
    "\n",
    "query_indices = sorted(np.random.choice(range(N), size=NUM_QUERIES, replace=False))\n",
    "print(\"Query indices:\", query_indices)\n",
    "\n",
    "# For each query, compute top-10 for Flatten, GMP, GAP and plot (5 queries x 3 feature types = 15 visualizations)\n",
    "for qidx in query_indices:\n",
    "    # Flatten features\n",
    "    idxs_f, scores_f = top_k_similar(flat_norm, qidx, k=TOP_K)\n",
    "    plot_query_and_results(features[\"paths\"], qidx, idxs_f, scores_f, title_prefix=f\"Flatten features - Query idx {qidx}\")\n",
    "\n",
    "    # GMP features\n",
    "    idxs_gmp, scores_gmp = top_k_similar(gmp_norm, qidx, k=TOP_K)\n",
    "    plot_query_and_results(features[\"paths\"], qidx, idxs_gmp, scores_gmp, title_prefix=f\"GMP features - Query idx {qidx}\")\n",
    "\n",
    "    # GAP features\n",
    "    idxs_gap, scores_gap = top_k_similar(gap_norm, qidx, k=TOP_K)\n",
    "    plot_query_and_results(features[\"paths\"], qidx, idxs_gap, scores_gap, title_prefix=f\"GAP features - Query idx {qidx}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
